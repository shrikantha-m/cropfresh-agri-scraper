name: AgriData Matrix Scraper

on:
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: "0 0 * * 0"  # Weekly on Sunday

jobs:
  scrape-all:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Scrape all data (55 commodities √ó 28 states √ó 10 years)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO_ID: ${{ secrets.HF_REPO_ID }}
        run: |
          echo "Starting CropFresh AgriData Scraper - Matrix Mode"
          echo "Target: 15,400 combinations (55 commodities √ó 28 states √ó 10 years)"
          
          # Read commodities and states
          COMMODITIES=$(cat config/commodities.json | jq -r '[.vegetables, .fruits, .leafy_greens, .cereals] | add | .[]')
          STATES=$(cat config/states.json | jq -r '.states[]')
          YEARS=("2015" "2016" "2017" "2018" "2019" "2020" "2021" "2022" "2023" "2024")
          
          # Initialize counters
          TOTAL=0
          SUCCESS=0
          FAILED=0
          
          # Create output directory
          mkdir -p scraped_data
          
          # Loop through all combinations
          for COMMODITY in $COMMODITIES; do
            for STATE in $STATES; do
              for YEAR in "${YEARS[@]}"; do
                TOTAL=$((TOTAL + 1))
                echo "[$TOTAL/15400] Processing: $COMMODITY | $STATE | $YEAR"
                
                # Run scraper
                if python scrapers/agmarknet_worker.py "$COMMODITY" "$STATE" "$YEAR"; then
                  SUCCESS=$((SUCCESS + 1))
                else
                  FAILED=$((FAILED + 1))
                  echo "‚ö†Ô∏è  Failed: $COMMODITY | $STATE | $YEAR"
                fi
                
                # Progress report every 100 combinations
                if [ $((TOTAL % 100)) -eq 0 ]; then
                  echo "üìä Progress: $TOTAL/15400 | ‚úÖ Success: $SUCCESS | ‚ùå Failed: $FAILED"
                fi
              done
            done
          done
          
          echo "\nüéâ Scraping Complete!"
          echo "Total: $TOTAL | Success: $SUCCESS | Failed: $FAILED"
      
      - name: Upload to Hugging Face
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO_ID: ${{ secrets.HF_REPO_ID }}
        run: python manager_upload.py
